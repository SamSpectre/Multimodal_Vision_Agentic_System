# Vision Platform Development Log

> **Purpose**: This document provides context for Claude Code sessions. Start each new session by saying: "Read DEVELOPMENT_LOG.md and continue where we left off."

---

## Project Overview

**Project Name**: Enterprise Multimodal Vision Platform
**Goal**: Build a production-ready, client-facing multimodal vision platform
**Tech Stack**: FastAPI + LangChain + Mistral OCR 3 + MediaPipe + GPT-4o Vision

**End Vision**: A platform clients can use via REST API to:
- Process documents (OCR, classification, data extraction)
- Analyze faces and emotions
- Process video for object detection

---

## Current Status

| Phase | Name | Status | Key Deliverables |
|-------|------|--------|------------------|
| 0-1 | Documents MVP | âœ… DONE | FastAPI + Mistral OCR 3 |
| 1.5 | Codebase Cleanup | ðŸ”œ NEXT | Remove clutter, trim unused code |
| 2 | Video Analysis | â³ After cleanup | Video + Face/Emotion/Object Detection |
| 3 | Async Processing | â³ Pending | Celery + Redis + Jobs |
| 4 | Multi-Tenant | â³ Pending | Auth + Rate Limiting |
| 5 | Client Deployment | â³ Future | Docker + CI/CD |

### Key Decision: Video-First Approach
Static image analysis was replaced with video processing. Video is the primary input for:
- Face detection (MediaPipe)
- Emotion analysis (GPT-4o Vision)
- Object detection (GPT-4o Vision)
- People counting

---

## Session 1 Summary (COMPLETED)

### What Was Built

Created a complete FastAPI-based document processing system with Mistral OCR 3.

### Files Created

```
Project-4_Vision&Langchain/
â”œâ”€â”€ .env                              # API keys (OPENAI, MISTRAL)
â”œâ”€â”€ requirements.txt                  # Updated with fastapi, uvicorn, mistralai
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                       # FastAPI app with lifespan, CORS, middleware
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ health.py                 # Health check endpoints (/live, /ready)
â”‚   â”‚   â””â”€â”€ documents.py              # Document processing endpoints
â”‚   â””â”€â”€ schemas/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base.py                   # Base Pydantic models
â”‚       â””â”€â”€ documents.py              # Document request/response schemas
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                   # Pydantic Settings with .env loading
â””â”€â”€ src/
    â”œâ”€â”€ clients/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ mistral_client.py         # Singleton Mistral client
    â””â”€â”€ tools/
        â””â”€â”€ mistral_ocr_tools.py      # OCR tools with @tool decorator
```

### API Endpoints Available

```
GET  /                           â†’ API info
GET  /docs                       â†’ Swagger UI (auto-generated)
GET  /api/v1/health/             â†’ Health status
GET  /api/v1/health/live         â†’ Kubernetes liveness probe
GET  /api/v1/health/ready        â†’ Kubernetes readiness probe
POST /api/v1/documents/ocr       â†’ OCR text extraction
POST /api/v1/documents/tables    â†’ Table extraction
POST /api/v1/documents/classify  â†’ Document classification
POST /api/v1/documents/analyze   â†’ Full analysis pipeline
POST /api/v1/documents/pdf       â†’ Multi-page PDF processing
POST /api/v1/documents/upload    â†’ File upload endpoint
GET  /api/v1/documents/status    â†’ Service status
```

### Key Patterns Learned

#### 1. Singleton Pattern
**File**: `src/clients/mistral_client.py`
```python
_client = None
def get_client():
    global _client
    if _client is None:
        _client = ExpensiveResource()
    return _client
```
**Why**: Expensive resources (API clients, DB connections, ML models) should only be instantiated once.

#### 2. @tool Decorator (LangChain)
**File**: `src/tools/mistral_ocr_tools.py`
```python
@tool
def process_document(path: str) -> str:
    """Docstring becomes the tool description for AI agents."""
    return result
```
**Why**: Converts functions into agent-callable tools with automatic schema generation.

#### 3. Pydantic Models
**File**: `api/schemas/*.py`
```python
class Request(BaseModel):
    field: str = Field(..., description="Required field")
```
**Why**: Type-safe validation, automatic API docs, error handling.

#### 4. FastAPI Lifespan
**File**: `api/main.py`
```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup code
    yield
    # Shutdown code
```
**Why**: Modern way to handle app startup/shutdown (initialize resources, cleanup).

#### 5. Health Checks
**File**: `api/routers/health.py`
- `/live` - Is the process running? (Kubernetes restarts if fails)
- `/ready` - Can it handle requests? (Load balancer removes if fails)

#### 6. Pydantic Settings
**File**: `config/settings.py`
```python
class Settings(BaseSettings):
    OPENAI_API_KEY: str = Field(...)
    model_config = SettingsConfigDict(env_file=".env")
```
**Why**: 12-factor app pattern - configuration from environment.

### Issues Resolved

1. **ModuleNotFoundError for langchain_core**
   - Fix: `pip install langchain-core langchain langchain-openai`

2. **API keys showing as NOT SET**
   - Cause: `load_dotenv()` without explicit path
   - Fix: Added explicit path in settings.py:
     ```python
     PROJECT_ROOT = Path(__file__).parent.parent
     ENV_FILE = PROJECT_ROOT / ".env"
     load_dotenv(dotenv_path=ENV_FILE)
     ```

---

## Phase 1.5: Codebase Cleanup (NEXT)

Before implementing the Video Analysis Module, clean up the existing codebase.

### Cleanup Tasks
1. Audit `src/` directory for unused legacy code
2. Remove legacy CLIs: `chat.py`, `ocr_agent.py` (root level)
3. Review `src/agents/` - remove if not integrated with API
4. Consolidate overlapping tool files in `src/tools/`
5. Clean up `requirements.txt` - remove unused deps
6. Update documentation files

### Files to Review for Removal
```
chat.py                    # Legacy CLI
ocr_agent.py               # Legacy CLI (root level)
graph.py                   # Review if still used
MULTI_AGENT_GUIDE.md       # May be outdated
src/agents/                # Review if integrated with API
```

---

## Phase 2: Video Analysis Module (AFTER CLEANUP)

### Overview
A unified video processing module where users upload videos and select what to analyze:
- **Face Detection** - Find faces throughout video (MediaPipe)
- **Emotion Analysis** - Analyze emotions on detected faces (GPT-4o)
- **Object Detection** - Identify objects in frames (GPT-4o)
- **People Counting** - Count and track people

### Learning Objectives
- **OpenCV** - Video loading, frame extraction, image manipulation
- **MediaPipe** - Real-time face detection optimized for video
- **Frame Sampling** - Smart frame selection (not every frame)
- **GPT-4o Vision** - Scene understanding, object detection, emotion analysis
- **Temporal Data** - Timestamped results, tracking across frames

### Files to Create

```
src/processors/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ video_processor.py           # OpenCV video handling
â””â”€â”€ video_analysis_pipeline.py   # Main orchestrator

src/models/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ face_detector.py             # MediaPipe face detection
â””â”€â”€ vision_analyzer.py           # GPT-4o emotion/object analysis

src/tools/
â””â”€â”€ video_tools.py               # LangChain @tool functions

api/routers/
â””â”€â”€ video.py                     # Video API endpoints

api/schemas/
â””â”€â”€ video.py                     # Pydantic models
```

### Implementation Steps

1. **Install Dependencies**
   ```bash
   pip install opencv-python mediapipe
   ```

2. **Create Video Processor** (`src/processors/video_processor.py`)
   - OpenCV video handling, frame extraction, sampling

3. **Create Face Detector** (`src/models/face_detector.py`)
   - MediaPipe wrapper for video frames

4. **Create Vision Analyzer** (`src/models/vision_analyzer.py`)
   - GPT-4o wrapper for emotion and object detection

5. **Create Video Pipeline** (`src/processors/video_analysis_pipeline.py`)
   - Orchestrates face detection, emotion, objects, people counting

6. **Create Video Tools** (`src/tools/video_tools.py`)
   - LangChain @tool functions

7. **Create Video Schemas** (`api/schemas/video.py`)
   - Pydantic models for requests/responses

8. **Create Video Router** (`api/routers/video.py`)
   - API endpoints

9. **Update Main App** (`api/main.py`)
   - Include video router

### API Endpoints to Add

```
POST /api/v1/video/analyze  â†’ Analyze video (faces, emotions, objects, people)
POST /api/v1/video/upload   â†’ Upload video file
GET  /api/v1/video/info     â†’ Get video metadata
POST /api/v1/video/frames   â†’ Extract specific frames
GET  /api/v1/video/status   â†’ Service status
```

---

## Future Phases (Brief)

### Phase 3: Async Processing
- Celery for background jobs (video processing takes time)
- Redis as message broker
- Job status tracking

### Phase 4: Async Processing
- Celery for background jobs
- Redis as message broker
- Job status tracking
- Files: `workers/celery_app.py`, `workers/tasks/`

### Phase 5: Multi-Tenant & Production
- API key authentication
- Rate limiting middleware
- Per-tenant configuration
- Prometheus metrics

### Phase 6: Client Deployment
- Docker containerization
- Docker Compose for full stack
- CI/CD with GitHub Actions
- Cloud deployment (AWS/GCP/Azure)

---

## Quick Start Commands

### Start Development Server
```bash
cd "C:\Users\samde\Langchain_Projects\Project-4_Vision&Langchain"

# Windows
.\.venv\Scripts\activate

# Linux/WSL
source venv/bin/activate

# Run server
uvicorn api.main:app --reload --port 8000
```

### Verify Setup
1. http://localhost:8000/docs - Swagger UI
2. http://localhost:8000/api/v1/health/ready - Check services
3. http://localhost:8000/api/v1/documents/status - Check Mistral

### Test Configuration
```bash
python config/settings.py
```

---

## Environment Variables (.env)

```
OPENAI_API_KEY=sk-proj-...
MISTRAL_API_KEY=...
```

---

## Dependencies (requirements.txt)

Key packages added:
- `fastapi>=0.109.0` - Web framework
- `uvicorn[standard]>=0.27.0` - ASGI server
- `mistralai>=1.0.0` - Mistral OCR 3
- `python-multipart>=0.0.6` - File uploads
- `structlog>=24.1.0` - Structured logging

To add for Phase 2:
- `mediapipe>=0.10.14` - Face detection
- `opencv-python>=4.9.0` - Image processing

---

## Project Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Application                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   /health   â”‚  â”‚  /documents â”‚  â”‚   /faces    â”‚  (Next) â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mistral OCR 3 â”‚    â”‚   MediaPipe   â”‚    â”‚  GPT-4o Vision â”‚
â”‚   (Documents) â”‚    â”‚    (Faces)    â”‚    â”‚   (Analysis)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  LangChain    â”‚
                    â”‚    Tools      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How to Continue Next Session

**Say to Claude Code:**
> "Read DEVELOPMENT_LOG.md and continue where we left off. We're starting Phase 2: Face/Emotion Module."

**What Claude should do:**
1. Read this file for context
2. Install MediaPipe
3. Create face detector model wrapper
4. Create emotion classifier
5. Create face tools
6. Create face schemas
7. Create face API endpoints
8. Update main app

---

## User Preferences

- **Learning Focus**: Understand each concept deeply, not just copy-paste
- **Approach**: Iterative, step-by-step development
- **Documentation**: Explain patterns as we implement them
- **Goal**: Build foundation for future complex enterprise projects

---

*Last Updated: Session 1 completion - Documents MVP done, Face/Emotion module next*
